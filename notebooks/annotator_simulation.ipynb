{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotator Simulation\n",
    "In this notebook, we simulate annotators for the classification data sets for which only the ground truth labels were given. Before executing this notebook, you need to download or create the data sets by running the notebook [`data_set_creation_download.ipynb`](./data_set_creation_download.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from evaluation.data_utils import DATA_PATH\n",
    "from evaluation.architecture_utils import get_gt_net\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from lfma.utils import (\n",
    "    annot_sim_clf_cluster,\n",
    "    compute_annot_perf_clf,\n",
    "    generate_expert_cluster_combinations,\n",
    ")\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "# Set random state to ensure reproducibility.\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "# Check device.\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotator Sets\n",
    "In the following, we define the simulation of annotator sets (described in the accompanied article) as data set configuration dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Configuration of annotator sets simulation per data set.\n",
    "configs_data_sets = [\n",
    "    {\n",
    "        \"data_set_name\": \"toy-classification\",\n",
    "        \"random_state\": 1,\n",
    "        \"n_annotators\": 10,\n",
    "        \"n_adversarial_annotators\": 1,\n",
    "        \"n_cluster_specialized_annotators\": 2,\n",
    "        \"n_target_specialized_annotators\": 1,\n",
    "        \"n_clusters\": 4,\n",
    "    },\n",
    "    {\n",
    "        \"data_set_name\": \"toy-classification\",\n",
    "        \"random_state\": 5,\n",
    "        \"n_annotators\": 100,\n",
    "        \"n_adversarial_annotators\": 10,\n",
    "        \"n_cluster_specialized_annotators\": 20,\n",
    "        \"n_target_specialized_annotators\": 10,\n",
    "        \"n_clusters\": 4,\n",
    "        \"name_appendix\": \"-inductive\",\n",
    "    },\n",
    "        {\n",
    "            \"data_set_name\": \"letter\",\n",
    "            \"random_state\": 6,\n",
    "            \"n_annotators\": 10,\n",
    "            \"n_adversarial_annotators\": 1,\n",
    "            \"n_cluster_specialized_annotators\": 2,\n",
    "            \"n_target_specialized_annotators\": 1,\n",
    "            \"n_clusters\": 10,\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"letter\",\n",
    "            \"random_state\": 7,\n",
    "            \"n_annotators\": 110,\n",
    "            \"n_adversarial_annotators\": 1,\n",
    "            \"n_cluster_specialized_annotators\": 2,\n",
    "            \"n_target_specialized_annotators\": 1,\n",
    "            \"n_random_annotators\": 100,\n",
    "            \"n_clusters\": 10,\n",
    "            \"name_appendix\": \"-random\",\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"letter\",\n",
    "            \"random_state\": 9,\n",
    "            \"n_annotators\": 100,\n",
    "            \"n_adversarial_annotators\": 10,\n",
    "            \"n_cluster_specialized_annotators\": 20,\n",
    "            \"n_target_specialized_annotators\": 10,\n",
    "            \"n_clusters\": 10,\n",
    "            \"name_appendix\": \"-inductive\",\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"fmnist\",\n",
    "            \"random_state\": 10,\n",
    "            \"n_annotators\": 10,\n",
    "            \"n_adversarial_annotators\": 1,\n",
    "            \"n_cluster_specialized_annotators\": 2,\n",
    "            \"n_target_specialized_annotators\": 1,\n",
    "            \"n_clusters\": 10,\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"fmnist\",\n",
    "            \"random_state\": 11,\n",
    "            \"n_annotators\": 110,\n",
    "            \"n_adversarial_annotators\": 1,\n",
    "            \"n_cluster_specialized_annotators\": 2,\n",
    "            \"n_target_specialized_annotators\": 1,\n",
    "            \"n_random_annotators\": 100,\n",
    "            \"n_clusters\": 10,\n",
    "            \"name_appendix\": \"-random\",\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"fmnist\",\n",
    "            \"random_state\": 13,\n",
    "            \"n_annotators\": 100,\n",
    "            \"n_adversarial_annotators\": 10,\n",
    "            \"n_cluster_specialized_annotators\": 20,\n",
    "            \"n_target_specialized_annotators\": 10,\n",
    "            \"n_clusters\": 10,\n",
    "            \"name_appendix\": \"-inductive\",\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"cifar10\",\n",
    "            \"random_state\": 14,\n",
    "            \"n_annotators\": 10,\n",
    "            \"n_adversarial_annotators\": 1,\n",
    "            \"n_cluster_specialized_annotators\": 2,\n",
    "            \"n_target_specialized_annotators\": 1,\n",
    "            \"n_clusters\": 10,\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"cifar10\",\n",
    "            \"random_state\": 15,\n",
    "            \"n_annotators\": 110,\n",
    "            \"n_adversarial_annotators\": 1,\n",
    "            \"n_cluster_specialized_annotators\": 2,\n",
    "            \"n_target_specialized_annotators\": 1,\n",
    "            \"n_random_annotators\": 100,\n",
    "            \"n_clusters\": 10,\n",
    "            \"name_appendix\": \"-random\",\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"cifar10\",\n",
    "            \"random_state\": 17,\n",
    "            \"n_annotators\": 100,\n",
    "            \"n_adversarial_annotators\": 10,\n",
    "            \"n_cluster_specialized_annotators\": 20,\n",
    "            \"n_target_specialized_annotators\": 10,\n",
    "            \"n_clusters\": 10,\n",
    "            \"name_appendix\": \"-inductive\",\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"svhn\",\n",
    "            \"random_state\": 18,\n",
    "            \"n_annotators\": 10,\n",
    "            \"n_adversarial_annotators\": 1,\n",
    "            \"n_cluster_specialized_annotators\": 2,\n",
    "            \"n_target_specialized_annotators\": 1,\n",
    "            \"n_clusters\": 10,\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"svhn\",\n",
    "            \"random_state\": 19,\n",
    "            \"n_annotators\": 110,\n",
    "            \"n_adversarial_annotators\": 1,\n",
    "            \"n_cluster_specialized_annotators\": 2,\n",
    "            \"n_target_specialized_annotators\": 1,\n",
    "            \"n_random_annotators\": 100,\n",
    "            \"n_clusters\": 10,\n",
    "            \"name_appendix\": \"-random\",\n",
    "        },\n",
    "        {\n",
    "            \"data_set_name\": \"svhn\",\n",
    "            \"random_state\": 21,\n",
    "            \"n_annotators\": 100,\n",
    "            \"n_adversarial_annotators\": 10,\n",
    "            \"n_cluster_specialized_annotators\": 20,\n",
    "            \"n_target_specialized_annotators\": 10,\n",
    "            \"n_clusters\": 10,\n",
    "            \"name_appendix\": \"-inductive\",\n",
    "        },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simulation\n",
    "In the following, we perform the simulation of the above configured annotator sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for data_dict in configs_data_sets:\n",
    "    data_set_name = data_dict.get(\"data_set_name\")\n",
    "    random_state = data_dict.get(\"random_state\", None)\n",
    "    n_annotators = data_dict.get(\"n_annotators\", 10)\n",
    "    n_adv_annotators = data_dict.get(\"n_adversarial_annotators\", 0)\n",
    "    n_cluster_spec_annotators = data_dict.get(\"n_cluster_specialized_annotators\", 0)\n",
    "    n_target_spec_annotators = data_dict.get(\"n_target_specialized_annotators\", 0)\n",
    "    n_random_annotators = data_dict.get(\"n_random_annotators\", 0)\n",
    "    n_clusters = data_dict.get(\"n_clusters\", 10)\n",
    "    name_appendix = data_dict.get(\"name_appendix\", \"\")\n",
    "    annotator_types = np.zeros(n_annotators, dtype=float)\n",
    "\n",
    "    print(data_set_name)\n",
    "\n",
    "    # Load data.\n",
    "    try:\n",
    "        X = np.load(f\"{DATA_PATH}/{data_set_name}-X.npy\")\n",
    "        y_true = np.load(f\"{DATA_PATH}/{data_set_name}-y-true.npy\")\n",
    "        classes = np.unique(y_true)\n",
    "        n_classes = len(classes)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"{e}. Continue with the next data set.\")\n",
    "        continue\n",
    "\n",
    "    # Transform potential images to vectors.\n",
    "    if data_set_name in [\"cifar10\", \"svhn\"]:\n",
    "        resnet_dict = get_gt_net(\n",
    "            data_set_name=data_set_name, n_classes=n_classes, n_features=None, dropout_rate=0, pretrained=True\n",
    "        )[0]\n",
    "        resnet = resnet_dict[\"gt_embed_x\"].to(DEVICE)\n",
    "        tensor_x = torch.Tensor(X)\n",
    "        transform = Resize((224, 224))\n",
    "        dataset = TensorDataset(tensor_x)\n",
    "        dataloader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "        X = []\n",
    "        with torch.no_grad():\n",
    "            for x in dataloader:\n",
    "                x_embed = resnet(transform(x[0].to(DEVICE))).cpu().numpy()\n",
    "                X.append(x_embed)\n",
    "        X = np.concatenate(X)\n",
    "    elif data_set_name in [\"fmnist\"]:\n",
    "        X = X.reshape(*X.shape[:-3], -1)\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    else:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Randomly generate accuracies.\n",
    "    random_state = check_random_state(random_state)\n",
    "    min_acc = 1 / n_classes\n",
    "    A = random_state.uniform(min_acc, 1, (n_annotators - n_target_spec_annotators - n_random_annotators) * n_clusters)\n",
    "    A = A.reshape((n_annotators - n_target_spec_annotators - n_random_annotators, n_clusters))\n",
    "\n",
    "    # Generate adversarial annotators.\n",
    "    A[:n_adv_annotators] = 0.05\n",
    "    annotator_types[:n_adv_annotators] = 1\n",
    "\n",
    "    # Generate specialized annotators who are either really well on a cluster or bad.\n",
    "    annotator_types[n_adv_annotators : n_adv_annotators + n_cluster_spec_annotators] = 2\n",
    "    cluster_indices = np.arange(n_clusters)\n",
    "    n_good_clusters = int(n_clusters / 2 + 0.5)\n",
    "    good_clusters_indices = generate_expert_cluster_combinations(\n",
    "        n_annotators=n_cluster_spec_annotators,\n",
    "        n_clusters=n_clusters,\n",
    "        n_expert_clusters=n_good_clusters,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    for a_idx, a in enumerate(\n",
    "        range(\n",
    "            n_adv_annotators,\n",
    "            n_adv_annotators + n_cluster_spec_annotators,\n",
    "        )\n",
    "    ):\n",
    "        A[a] = 0.05\n",
    "        A[a, good_clusters_indices[a_idx]] = 0.95\n",
    "\n",
    "    # Simulate labels of cluster-based annotators.\n",
    "    if len(A) > 0:\n",
    "        y, y_cluster = annot_sim_clf_cluster(\n",
    "            X=X,\n",
    "            y_true=y_true,\n",
    "            cluster_annot_perfs=A,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "    else:\n",
    "        y = np.zeros((X.shape[0], 0))\n",
    "        y_cluster = MiniBatchKMeans(n_clusters=n_clusters).fit_predict(X)\n",
    "\n",
    "    # Generate specialized annotators who are either really well on a cluster or bad.\n",
    "    if n_target_spec_annotators > 0:\n",
    "        annotator_types[y.shape[1] : y.shape[1] + n_target_spec_annotators] = 3\n",
    "        A = np.full((n_target_spec_annotators, n_classes), 0.05)\n",
    "        class_indices = np.arange(n_classes)\n",
    "        n_good_classes = int(n_classes / 2 + 0.5)\n",
    "        good_class_indices = generate_expert_cluster_combinations(\n",
    "            n_annotators=n_target_spec_annotators,\n",
    "            n_clusters=n_classes,\n",
    "            n_expert_clusters=n_good_classes,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        for a in range(n_target_spec_annotators):\n",
    "            A[a, good_class_indices[a]] = 0.95\n",
    "\n",
    "        # Simulate labels of target-based annotators.\n",
    "        y_target, _ = annot_sim_clf_cluster(\n",
    "            X=y_true.reshape(-1, 1),\n",
    "            y_true=y_true,\n",
    "            cluster_annot_perfs=A,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        y = np.hstack((y, y_target))\n",
    "\n",
    "    if n_random_annotators > 0:\n",
    "        annotator_types[y.shape[1] : y.shape[1] + n_random_annotators] = 4\n",
    "        y_random = np.column_stack(\n",
    "            [random_state.choice(classes, replace=True, size=len(X)) for _ in range(n_random_annotators)]\n",
    "        )\n",
    "        y = np.column_stack((y, y_random))\n",
    "\n",
    "    # Generate annotator features.\n",
    "    n_annotator_types = len(np.unique(annotator_types))\n",
    "    A = np.zeros((n_annotators, n_annotator_types + n_classes + n_clusters))\n",
    "    A[:, :n_annotator_types] = OneHotEncoder(sparse=False).fit_transform(annotator_types.reshape(-1, 1))\n",
    "    for a_idx in range(n_annotators):\n",
    "        class_acc = np.diag(\n",
    "            confusion_matrix(y_true=y_true, y_pred=y[:, a_idx], labels=np.arange(n_classes), normalize=\"true\")\n",
    "        )\n",
    "        A[a_idx, n_annotator_types : n_annotator_types + n_classes] = class_acc\n",
    "        for c in range(n_clusters):\n",
    "            is_cluster_c = np.equal(y_cluster, c)\n",
    "            A[a_idx, n_annotator_types + n_classes + c] = np.equal(y[is_cluster_c, a_idx], y_true[is_cluster_c]).mean()\n",
    "\n",
    "    # Print performances of simulated annotators.\n",
    "    performances = compute_annot_perf_clf(y_true=y_true, y=y)\n",
    "    display(HTML(performances.to_html()))\n",
    "\n",
    "    # Save annotator features and simulated annotations.\n",
    "    np.save(f\"{DATA_PATH}/{data_set_name}-A{name_appendix}.npy\", A.astype(np.float32))\n",
    "    np.save(f\"{DATA_PATH}/{data_set_name}-y{name_appendix}.npy\", y.astype(np.int64))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
