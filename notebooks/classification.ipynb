{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Multi-annotator Deep Learning for Classification\n",
    "In this notebook, we are going to reproduce the three visualizations provided in the accompanied article. Concretely, we demonstrate how to\n",
    "- obtain the predictions of different MaDL variants for the two-dimensional data set TOY (corresponding to `RQ=\"p1+p2+independent\"`),\n",
    "- visualize the learned annotator embeddings and weights for the data set LETTER (corresponding to `RQ=\"p3+p4+interdependent\"` or `RQ=\"p3+p4+random-interdependent\"`),\n",
    "- and infer the performances of unknown annotators (inductive learning) for the data set TOY (corresponding to `RQ=\"p5+p6+inductive\"`).\n",
    "\n",
    "Reproducing the plots for different MaDL variants requires varying the parameters `embed_x` and `confusion_matrix`, where we have the following mapping:\n",
    "- MaDL(not X,I): `embed_x=\"none\", confusion_matrix=\"isotropic\"`,\n",
    "- MaDL(not X,F): `embed_x=\"none\", confusion_matrix=\"diagonal\"`,\n",
    "- MaDL(X,I): `embed_x=\"learned\", confusion_matrix=\"isotropic\"`,\n",
    "- and MaDL(X,F): `embed_x=\"learned\", confusion_matrix=\"diagonal\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfma.utils import StoreBestModuleStateDict\n",
    "\n",
    "from skactiveml.utils import majority_vote\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "from torch import cuda\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from lfma.utils import (\n",
    "    LitProgressBar,\n",
    "    compute_annot_perf_clf,\n",
    "    plot_annot_perfs_clf,\n",
    "    introduce_missing_annotations,\n",
    ")\n",
    "from evaluation.data_utils import load_data, DATA_PATH\n",
    "from evaluation.architecture_utils import instantiate_madl_classifier\n",
    "\n",
    "# Set random state to ensure reproducibility.\n",
    "RANDOM_STATE = 1\n",
    "\n",
    "# Constant to represent annotations that are not available.\n",
    "MISSING_LABEL = -1\n",
    "\n",
    "# Define the research question (RQ) variable according to the initial description of this notebook.\n",
    "RQ = \"p3+p4+interdependent\"\n",
    "\n",
    "# Define setup according to selection research question.\n",
    "if RQ == \"p1+p2+independent\":\n",
    "    DATA_TYPE = \"none\"\n",
    "    MISSING_LABEL_RATIO = 0.8\n",
    "    MAX_EPOCHS = 100\n",
    "    DATA_SET_NAME = \"toy-classification\"\n",
    "    ANNOTATOR_FEATURES = False\n",
    "    DROPOUT = 0.5\n",
    "    VIS_POINTS = \"train\"\n",
    "    LR = 0.01\n",
    "elif RQ == \"p3+p4+interdependent\":\n",
    "    DATA_TYPE = \"correlated\"\n",
    "    MISSING_LABEL_RATIO = 0.8\n",
    "    MAX_EPOCHS = 5\n",
    "    DATA_SET_NAME = \"letter\"\n",
    "    ANNOTATOR_FEATURES = False\n",
    "    DROPOUT = 0.0\n",
    "    VIS_POINTS = \"train\"\n",
    "    LR = 0.005\n",
    "elif RQ == \"p3+p4+random-interdependent\":\n",
    "    DATA_TYPE = \"rand-dep_10_100\"\n",
    "    MISSING_LABEL_RATIO = 0.8\n",
    "    MAX_EPOCHS = 5\n",
    "    DATA_SET_NAME = \"letter\"\n",
    "    ANNOTATOR_FEATURES = False\n",
    "    DROPOUT = 0.0\n",
    "    VIS_POINTS = \"train\"\n",
    "    LR = 0.005\n",
    "elif RQ == \"p5+p6+inductive\":\n",
    "    DATA_TYPE = \"inductive_5\"\n",
    "    MISSING_LABEL_RATIO = 0.98\n",
    "    MAX_EPOCHS = 100\n",
    "    DATA_SET_NAME = \"toy-classification\"\n",
    "    ANNOTATOR_FEATURES = True\n",
    "    DROPOUT = 0.0\n",
    "    VIS_POINTS = \"test\"\n",
    "    LR = 0.01\n",
    "else:\n",
    "    raise ValueError(\"Invalid value for `RQ`. See introduction of this notebook to check the possible options.\")\n",
    "\n",
    "# Training setup.\n",
    "TRAINER_DICT = {\n",
    "    \"max_epochs\": MAX_EPOCHS,\n",
    "    \"accelerator\": \"gpu\" if cuda.is_available() else \"cpu\",\n",
    "    \"devices\": 1 if cuda.is_available() else None,\n",
    "    \"callbacks\": [StoreBestModuleStateDict(score_name=\"val_acc\", maximize=True), LitProgressBar()],\n",
    "    \"logger\": False,\n",
    "    \"enable_checkpointing\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load data.\n",
    "ds = load_data(\n",
    "    data_set_name=DATA_SET_NAME,\n",
    "    use_annotator_features=ANNOTATOR_FEATURES,\n",
    "    data_path=DATA_PATH,\n",
    "    preprocess=True,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_repeats=1,\n",
    "    valid_size=0.05,\n",
    "    test_size=0.2,\n",
    "    data_type=DATA_TYPE,\n",
    ")\n",
    "classes = np.unique(ds[\"y_true\"])\n",
    "n_classes = len(classes)\n",
    "n_samples = ds[\"X\"].shape[0]\n",
    "n_features = ds[\"X\"].shape[1]\n",
    "n_annotators = ds[\"A\"].shape[0]\n",
    "n_ap_features = ds[\"A\"].shape[1]\n",
    "\n",
    "# Introduce missing annotations.\n",
    "ds[\"y_partial\"] = introduce_missing_annotations(\n",
    "    y=ds[\"y\"],\n",
    "    percentage=MISSING_LABEL_RATIO,\n",
    "    missing_label=MISSING_LABEL,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "test_annot_indices = np.arange(n_annotators)\n",
    "inductive_annot_indices = None\n",
    "if \"inductive\" in DATA_TYPE:\n",
    "    splits = DATA_TYPE.split(\"_\")\n",
    "    n_test_annot = int(splits[1])\n",
    "    inductive_annot_indices = np.arange(0, n_annotators, n_annotators // n_test_annot).astype(int)\n",
    "    ds[\"y_partial\"][:, inductive_annot_indices] = -1\n",
    "    test_annot_indices = np.setdiff1d(test_annot_indices, inductive_annot_indices)\n",
    "\n",
    "# Compute majority vote considering missing annotations.\n",
    "ds[\"y_mv\"] = majority_vote(\n",
    "    y=ds[\"y_partial\"],\n",
    "    classes=classes,\n",
    "    missing_label=MISSING_LABEL,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# Evaluate annotator accuracies.\n",
    "print(\"Annotator accuracies: \")\n",
    "compute_annot_perf_clf(ds[\"y_true\"], ds[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_loader_dict = {\"batch_size\": 64, \"shuffle\": True}\n",
    "val_data_loader_dict = {\"batch_size\": 256, \"shuffle\": False}\n",
    "fit_dict = {\n",
    "    \"X\": ds[\"X\"][ds[\"train\"][0]],\n",
    "    \"y\": ds[\"y_partial\"][ds[\"train\"][0]],\n",
    "    \"X_val\": ds[\"X\"][ds[\"valid\"][0]],\n",
    "    \"y_val\": ds[\"y_true\"][ds[\"valid\"][0]],\n",
    "    \"data_loader_dict\": data_loader_dict,\n",
    "    \"val_data_loader_dict\": val_data_loader_dict,\n",
    "}\n",
    "default_params = {\n",
    "    \"data_set_name\": DATA_SET_NAME,\n",
    "    \"classes\": classes,\n",
    "    \"n_features\": n_features,\n",
    "    \"optimizer\": AdamW,\n",
    "    \"optimizer_dict\": {\"lr\": LR, \"weight_decay\": 0.0},\n",
    "    \"lr_scheduler\": CosineAnnealingLR,\n",
    "    \"lr_scheduler_dict\": {\"T_max\": 100},\n",
    "    \"dropout_rate\": DROPOUT,\n",
    "    \"trainer_dict\": TRAINER_DICT,\n",
    "    \"missing_label\": MISSING_LABEL,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "}\n",
    "\n",
    "# MaDL parameters.\n",
    "eta = 0.8\n",
    "embed_size = 16\n",
    "ap_use_residual = True\n",
    "alpha = 1.25\n",
    "beta = 0.25\n",
    "ap_sim_func = \"rbf\"\n",
    "confusion_matrix = \"diagonal\"\n",
    "embed_x = \"learned\"\n",
    "model_name = f\"madl_{embed_x}_{confusion_matrix}\"\n",
    "ap_use_outer_product = True\n",
    "\n",
    "# Set annotator features.\n",
    "fit_dict[\"A\"] = ds[\"A\"]\n",
    "\n",
    "# Create MaDL instance.\n",
    "clf = instantiate_madl_classifier(\n",
    "    n_ap_features=n_ap_features,\n",
    "    eta=eta,\n",
    "    embed_size=embed_size,\n",
    "    ap_use_outer_product=ap_use_outer_product,\n",
    "    ap_use_residual=ap_use_residual,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    confusion_matrix=confusion_matrix,\n",
    "    embed_x=embed_x,\n",
    "    **default_params,\n",
    ")\n",
    "\n",
    "# Train MaDL instance.\n",
    "clf = clf.fit(**fit_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate Classification Accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Quantitative Evaluation\n",
    "for d in [\"train\", \"valid\", \"test\"]:\n",
    "    P_perf = clf.predict_annotator_perf(ds[\"X\"][ds[d][0]], data_loader_dict=val_data_loader_dict)\n",
    "    perf = P_perf.mean(axis=0)\n",
    "    acc = clf.score(ds[\"X\"][ds[d][0]], ds[\"y_true\"][ds[d][0]])\n",
    "    print(f\"{d} classification accuracy: {acc}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize Predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize predictions for two-dimensional data sets.\n",
    "if n_features == 2:\n",
    "    annotator_indices = inductive_annot_indices if \"inductive\" in DATA_TYPE else np.arange(n_annotators)\n",
    "    y = ds[\"y\"] if \"inductive\" in DATA_TYPE else ds[\"y_partial\"]\n",
    "    A = ds[\"A\"][annotator_indices]\n",
    "    appendix = \"\" if DATA_TYPE == \"none\" else \"-\" + DATA_TYPE\n",
    "    plot_annot_perfs_clf(\n",
    "        X=ds[\"X\"][ds[VIS_POINTS][0]],\n",
    "        y_true=ds[\"y_true\"][ds[VIS_POINTS][0]],\n",
    "        y_full=ds[\"y\"][ds[VIS_POINTS][0]][:, annotator_indices],\n",
    "        y=y[ds[VIS_POINTS][0]][:, annotator_indices],\n",
    "        clf=clf,\n",
    "        missing_label=MISSING_LABEL,\n",
    "        cmap_clf=\"winter\",\n",
    "        cmap_annot=\"Purples\",\n",
    "        filepath=f\"./toy-{model_name}{appendix}\",\n",
    "        A=A,\n",
    "        plot_colorbar=False,\n",
    "        figsize=(6, 6),\n",
    "        plot_accuracies=False,\n",
    "        markersize=120,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize Learned Annotator Embeddings and Weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_kernels\n",
    "\n",
    "if hasattr(clf, \"compute_annotator_embeddings\"):\n",
    "    annotator_groups_legend = {\n",
    "        0: (\"adversarial\", \"#4d4d4dff\"),\n",
    "        1: (\"cluster-specialized\", \"#008080ff\"),\n",
    "        2: (\"common\", \"#2a7fffff\"),\n",
    "        3: (\"class-specialized\", \"#800080ff\"),\n",
    "        4: (\"random (interdependent)\", \"#784421\"),\n",
    "        5: (\"adversarial (interdependent)\", \"k\"),\n",
    "        6: (\"cluster-specialized (interdependent)\", \"#44aa00\"),\n",
    "        7: (\"class-specialized (interdependent)\", \"m\"),\n",
    "    }\n",
    "    annotator_groups = [0, 1, 1, 2, 2, 2, 2, 2, 2, 3]\n",
    "    if DATA_TYPE == \"rand-dep_10_100\":\n",
    "        annotator_groups += [4] * 90\n",
    "    elif DATA_TYPE == \"correlated\":\n",
    "        annotator_groups += [5, 6, 7] * 10\n",
    "        annotator_groups[0] = 5\n",
    "        annotator_groups[1] = 6\n",
    "        annotator_groups[9] = 7\n",
    "    elif \"inductive\" in DATA_TYPE:\n",
    "        annotator_groups = [0] * 10 + [1] * 20 + [2] * 60 + [3] * 10\n",
    "    annotator_groups = np.array(annotator_groups)\n",
    "    unique_annotator_groups = np.unique(annotator_groups)\n",
    "    A_embed = clf.compute_annotator_embeddings()\n",
    "    S = pairwise_kernels(A_embed, metric=\"rbf\", gamma=clf.module_.gamma.detach().cpu().numpy())\n",
    "    weights = 1 / np.sum(S, axis=-1)\n",
    "    weights /= weights.sum(axis=-1)\n",
    "    weights = n_annotators * weights\n",
    "    f, ax = plt.subplots(figsize=(6, 6))\n",
    "    A_transformed = MDS(metric=\"precomputed\", random_state=RANDOM_STATE, n_components=2).fit_transform(-S)\n",
    "    for g in unique_annotator_groups:\n",
    "        is_g = annotator_groups == g\n",
    "        plt.scatter(\n",
    "            A_transformed[is_g, 0],\n",
    "            A_transformed[is_g, 1],\n",
    "            c=annotator_groups_legend[g][1],\n",
    "            label=annotator_groups_legend[g][0],\n",
    "            s=120,\n",
    "        )\n",
    "    plt.legend()\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    plt.margins(0.1, 0.1)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.savefig(f\"./embeddings-{DATA_TYPE}-{DATA_SET_NAME}.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.show()\n",
    "    f, ax = plt.subplots(figsize=(6, 6))\n",
    "    bars = np.arange(len(unique_annotator_groups))\n",
    "    for g_idx, g in enumerate(unique_annotator_groups):\n",
    "        is_g = annotator_groups == g\n",
    "        weight_g = weights[is_g].mean()\n",
    "        bar_ax = plt.bar(annotator_groups_legend[g][0], weight_g, color=annotator_groups_legend[g][1])\n",
    "    for bar_ax in ax.containers:\n",
    "        ax.bar_label(bar_ax)\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    plt.margins(0, 0.1)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.savefig(f\"./weights-{DATA_TYPE}-{DATA_SET_NAME}.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
